import argparseimport loggingimport torch.nn.functional as Fimport numpy as npimport torchfrom torch.utils.tensorboard import SummaryWriterfrom gsBranch import arguments, scenefrom gsBranch.arguments import ModelParams, PipelineParams, OptimizationParamsfrom gsBranch.scene import Scene,GaussianModelfrom gsBranch.utils.general_utils import safe_statefrom gsBranch.arguments import ModelParams, PipelineParams, OptimizationParamsimport uuidfrom tqdm import tqdmfrom gsBranch.utils.image_utils import psnrimport sysimport osimport torchfrom random import randintfrom gsBranch.utils.loss_utils import l1_loss, ssimfrom gsBranch.gaussian_renderer import render, network_guifrom pyhocon import ConfigFactory, HOCONConverterimport cv2 as cvfrom udfBranch.dataset.dataset import Datasetfrom udfBranch.loss.loss import ColorLossfrom udfBranch.models.fields import NeRF, UDFNetwork, SingleVarianceNetwork, ResidualRenderingNetwork, BetaNetworkfrom udfBranch.models.udf_renderer_blending import UDFRendererBlendingdef parse_arguments():    """       Parses command line arguments.       This function uses the argparse library to define and parse command line arguments. It sets up several arguments,       including model parameters, optimization parameters, and pipeline parameters, as well as an argument for specifying       the data directory. After parsing the arguments, the function returns a namespace object containing all specified       arguments.       Returns:           args: A namespace object containing command line arguments.       """    # Initialize the command line argument parser    parser = argparse.ArgumentParser()    # Add model parameter configuration    lp = ModelParams(parser)    # Add optimization parameter configuration    op = OptimizationParams(parser)    # Add pipeline parameter configuration    pp = PipelineParams(parser)    # Define a command line argument for specifying the location of the data directory    parser.add_argument("--data_dir", type=str, default="./data/", help="data directory")    # 以下是3dgs中照搬的参数    parser.add_argument('--ip', type=str, default="127.0.0.1")    parser.add_argument('--port', type=int, default=6009)    parser.add_argument('--debug_from', type=int, default=-1)    parser.add_argument('--detect_anomaly', action='store_true', default=False)    parser.add_argument("--test_iterations", nargs="+", type=int, default=[7_000, 30_000])    parser.add_argument("--save_iterations", nargs="+", type=int, default=[7_000, 30_000])    parser.add_argument("--quiet", action="store_true")    parser.add_argument("--checkpoint_iterations", nargs="+", type=int, default=[])    parser.add_argument("--start_checkpoint", type=str, default=None)    # UDF中的参数    parser = argparse.ArgumentParser()    parser.add_argument('--udfconf', type=str, default='./confs/base.conf')    parser.add_argument('--mode', type=str, default='train')    parser.add_argument('--model_type', type=str, default='')    parser.add_argument('--threshold', type=float, default=0.005)    parser.add_argument('--is_continue', default=False, action="store_true")    parser.add_argument('--is_finetune', default=False, action="store_true")    parser.add_argument('--reg_weights_schedule', default=False, action="store_true",                        help='the schedule of regularization weights')    parser.add_argument('--vis_ray', default=False, action="store_true", help='visualize the udf of a ray for debug')    parser.add_argument('--gpu', type=int, default=0)    parser.add_argument('--resolution', type=int, default=128)    parser.add_argument('--case', type=str, default='', help='the object name or index of a dataset')    parser.add_argument('--learning_rate', type=float, default=0)    parser.add_argument('--learning_rate_geo', type=float, default=0,                        help='the learning rate of udf network, if do not use the global learning rate')    parser.add_argument('--sparse_weight', type=float, default=0, help='the weight of geo regularizer')    # Parse the command line arguments and return    args = parser.parse_args(sys.argv[1:])    return args,lp,op,ppclass Trainer:    def __init__(self, args, lp, op, pp, conf_path, mode='train', case='CASE_NAME', model_type='', is_continue=False):        self.args = args        self.lp = lp        self.op = op        self.pp = pp        self.device = torch.device('cuda')        '''        接下来进行UDF branch的初始化        '''        self.conf_path = conf_path        f = open(self.conf_path)        conf_text = f.read()        conf_text = conf_text.replace('CASE_NAME', case)        f.close()        # 加载Configurations并且将配置信息存入self.conf中        self.conf = ConfigFactory.parse_string(conf_text)        self.conf['dataset.data_dir'] = self.conf['dataset.data_dir'].replace('CASE_NAME', case)        # modify the setting based on input        if args.learning_rate > 0:            self.conf['train']['learning_rate'] = args.learning_rate        if args.learning_rate_geo > 0:            self.conf['train']['learning_rate_geo'] = args.learning_rate_geo        if args.sparse_weight > 0:            self.conf['train']['sparse_weight'] = args.sparse_weight        # 设置 exp 的地址        self.base_exp_dir = os.path.join(self.conf['general.base_exp_dir'], self.conf['general.expname'])        os.makedirs(self.base_exp_dir, exist_ok=True)        # 加载dataset        self.dataset_name = self.conf.get_string('dataset.dataset_name', default='general')        self.dataset = Dataset(self.conf['dataset'])        self.iter_step = 0        # 加载参数        # trainning parameters        self.end_iter = self.conf.get_int('train.end_iter')        self.save_freq = self.conf.get_int('train.save_freq')        self.report_freq = self.conf.get_int('train.report_freq')        self.val_freq = self.conf.get_int('train.val_freq')        self.val_mesh_freq = self.conf.get_int('train.val_mesh_freq')        self.batch_size = self.conf.get_int('train.batch_size')        self.validate_resolution_level = self.conf.get_int('train.validate_resolution_level')        self.use_white_bkgd = self.conf.get_bool('train.use_white_bkgd')        # setting about learning rate schedule        self.learning_rate = self.conf.get_float('train.learning_rate')        self.learning_rate_geo = self.conf.get_float('train.learning_rate_geo')        self.learning_rate_alpha = self.conf.get_float('train.learning_rate_alpha')        self.warm_up_end = self.conf.get_float('train.warm_up_end', default=0.0)        self.anneal_end = self.conf.get_float('train.anneal_end', default=0.0)        # don't train the udf network in the early steps        self.fix_geo_end = self.conf.get_float('train.fix_geo_end', default=500)        self.reg_weights_schedule = args.reg_weights_schedule        self.warmup_sample = self.conf.get_bool('train.warmup_sample', default=False)  # * training schedule        # whether the udf network and appearance network share the same learning rate        self.same_lr = self.conf.get_bool('train.same_lr', default=False)        # weights        self.igr_weight = self.conf.get_float('train.igr_weight')        self.igr_ns_weight = self.conf.get_float('train.igr_ns_weight', default=0.0)        self.mask_weight = self.conf.get_float('train.mask_weight')        self.sparse_weight = self.conf.get_float('train.sparse_weight', default=0.0)        # loss functions        self.color_loss_func = ColorLoss(**self.conf['color_loss'])        self.color_base_weight = self.conf.get_float('color_loss.color_base_weight', 0.0)        self.color_weight = self.conf.get_float('color_loss.color_weight', 0.0)        self.color_pixel_weight = self.conf.get_float('color_loss.color_pixel_weight', 0.0)        self.color_patch_weight = self.conf.get_float('color_loss.color_patch_weight', 0.0)        self.is_continue = is_continue        self.is_finetune = args.is_finetune        self.vis_ray = args.vis_ray  # visualize a ray for debug        self.mode = mode        self.model_type = self.conf['general.model_type']        if model_type != '':  # overwrite            self.model_type = model_type        self.model_list = []        self.writer = None        # Networks        params_to_train = []        params_to_train_nerf = []        params_to_train_geo = []        self.nerf_outside = None        self.nerf_coarse = None        self.nerf_fine = None        self.sdf_network_fine = None        self.udf_network_fine = None        self.variance_network_fine = None        self.color_network_coarse = None        self.color_network_fine = None        # 这NeRF用在这里干啥的？        self.nerf_outside = NeRF(**self.conf['model.nerf']).to(self.device)        self.udf_network_fine = UDFNetwork(**self.conf['model.udf_network']).to(self.device)        # 这俩网络干啥的？？        self.variance_network_fine = SingleVarianceNetwork(**self.conf['model.variance_network']).to(self.device)        self.color_network_fine = ResidualRenderingNetwork(**self.conf['model.rendering_network']).to(self.device)        self.beta_network = BetaNetwork(**self.conf['model.beta_network']).to(self.device)        params_to_train_nerf += list(self.nerf_outside.parameters())        params_to_train_geo += list(self.udf_network_fine.parameters())        params_to_train += list(self.variance_network_fine.parameters())        params_to_train += list(self.color_network_fine.parameters())        params_to_train += list(self.beta_network.parameters())        # 设置 optimizer        self.optimizer = torch.optim.Adam(            [{'params': params_to_train_geo, 'lr': self.learning_rate_geo}, {'params': params_to_train},             {'params': params_to_train_nerf}],            lr=self.learning_rate)        # 渲染对象        self.renderer = UDFRendererBlending(self.nerf_outside,                                            self.udf_network_fine,                                            self.variance_network_fine,                                            self.color_network_fine,                                            self.beta_network,                                            **self.conf['model.udf_renderer'])        # TODO Load checkpoint 这里需要加入原函数中很多东西，而我们的checkpoint是不是应该重新写？因为需要两个模型同时的checkpoint吧        # latest_model_name = None        # if is_continue:        #     model_list_raw = os.listdir(os.path.join(self.base_exp_dir, 'checkpoints'))        #     model_list = []        #     for model_name in model_list_raw:        #         if model_name[-3:] == 'pth':        #             # if model_name[-3:] == 'pth' and int(model_name[5:-4]) <= self.end_iter:        #             model_list.append(model_name)        #     model_list.sort()        #     latest_model_name = model_list[-1]        #        # if latest_model_name is not None:        #     logging.info('Find checkpoint: {}'.format(latest_model_name))        #     self.load_checkpoint(latest_model_name)        #        # if self.mode[:5] == 'train':        #     self.file_backup()    def training(        self,            dataset,            opt,            pipe,            testing_iterations,            saving_iterations,            checkpoint_iterations,            checkpoint,            debug_from,    ):        # 应该通过sfm首先初始化点云，这个点云用作3dgs的训练        # TODO 或许这里可以换成SLAM来初始化点云（ https://github.com/yanyan-li/gaussian-splatting-using-PlanarSLAM?tab=readme-ov-file ），借鉴一下GeoGaussian        # TODO 也可以考虑用 COLMAP-FREE GS 来进行渲染？        first_iter = 0        # 初始化        # Gaussian model Initialization        gaussians = GaussianModel(dataset.sh_degree)        # 场景的数据加载        # 就是利用COLMAP的初始化        # 已经完成了点云初始化：            # 如果没有加载迭代模型，点云数据是从场景信息中复制并创建高斯模型            # 如果加载了迭代模型，则直接从模型路径加载点云文件初始化高斯模型        # 对象中存储了相机数据        scene = Scene(dataset, gaussians)        # 设置训练过程的初始化参数和优化器。        # 此方法根据传入的训练参数初始化对象的某些属性，并配置优化器以适应特定的学习率策略。        gaussians.training_setup(opt)        # 看本次运行的时候是不是从checkpoint来开始的，如果是，则加载checkpoint的时候的模型参数以及训练次数        if checkpoint:            (model_params, first_iter) = torch.load(checkpoint)            gaussians.restore(model_params, opt)        # 根据背景设置初始化背景色        bg_color = [1, 1, 1] if dataset.white_background else [0, 0, 0]        background = torch.tensor(bg_color, dtype=torch.float32, device="cuda")        # 初始化渲染的开始和结束事件，用于计算渲染时间        iter_start = torch.cuda.Event(enable_timing=True)        iter_end = torch.cuda.Event(enable_timing=True)        # 初始化 视图堆栈 和 训练日志的累积损失        viewpoint_stack = None        ema_loss_for_log = 0.0        # 设置进度条        progress_bar = tqdm(range(first_iter, opt.iterations), desc="Training progress")        first_iter += 1        # TODO 两个网络需要在同一个训练循环中进行训练，因此需要整合两者的训练iters        # 两个网络先分开训练，然后在一些时候进行一个对另一个的指导，然后再在某个时候，反过来指导一次，后面再分开训练得到最终结果        for iter in range(first_iter, opt.iterations + 1):            pass    def train_gs(self):        pass    def train_udf(self):        """        训练用户定义函数（UDF）的函数。        这个函数包含了训练过程中的所有步骤，例如更新学习率、调整颜色损失权重、渲染图像等。        它使用了PyTorch和一些自定义的损失函数和渲染器来逐步优化模型。        参数:        self: 类的实例，包含了训练所需的所有属性，如优化器、学习率、数据集等。        """        # 随机重排图像顺序，以增加训练的多样性        image_perm = torch.randperm(self.dataset.n_images)        # 初始化TensorBoard日志记录器        self.writer = SummaryWriter(log_dir=os.path.join(str(self.base_exp_dir), 'logs'))        # 计算剩余的迭代步数        res_step = self.end_iter - self.iter_step        # 设置优化器的学习率        for g in self.optimizer.param_groups:            g['lr'] = self.learning_rate        # 初始化beta标志        beta_flag = True        # 迭代训练过程        for iter_i in tqdm(range(res_step)):            # 根据是否使用相同的学习率更新学习率            if self.same_lr:                self.udf_update_learning_rate(start_g_id=0)            else:                self.udf_update_learning_rate(start_g_id=1)                self.udf_update_learning_rate_geo()            # 调整颜色损失权重            color_base_weight, color_weight, color_pixel_weight, color_patch_weight = self.udf_adjust_color_loss_weights()            # 根据当前迭代步数获取图像索引，并准备随机射线和对应的地面 truth            img_idx = image_perm[self.iter_step % len(image_perm)]            sample = self.dataset.gen_random_rays_patches_at(                img_idx, self.batch_size,                crop_patch=color_patch_weight > 0.0, h_patch_size=self.color_loss_func.h_patch_size)            # 解析样本数据            data = sample['rays']            rays_uv = sample['rays_ndc_uv']            gt_patch_colors = sample['rays_patch_color']            gt_patch_mask = sample['rays_patch_mask']            # 根据颜色像素权重和颜色块权重决定是否加载参考和源图像信息            if color_pixel_weight > 0. or color_patch_weight > 0.:                # todo: this load is very slow                ref_c2w, src_c2ws, src_intrinsics, src_images, img_wh = self.dataset.get_ref_src_info(img_idx)                src_w2cs = torch.inverse(src_c2ws)            else:                ref_c2w, src_c2ws, src_w2cs, src_intrinsics, src_images = None, None, None, None, None            # todo load supporting images            # 提取射线的起点、方向、真实RGB值和遮罩            rays_o, rays_d, true_rgb, mask = data[:, :3], data[:, 3: 6], data[:, 6: 9], data[:, 9: 10]            # 计算射线的近远裁剪距离            near, far = self.dataset.near_far_from_sphere(rays_o, rays_d)            # 将遮罩转换为浮点格式            mask = (mask > 0.5).float()            # 避免除以零            mask_sum = mask.sum() + 1e-5            # 使用渲染器渲染图像            render_out = self.renderer.render(rays_o, rays_d, near, far,                                              flip_saturation=self.udf_get_flip_saturation(),                                              color_maps=src_images if color_pixel_weight > 0. else None,                                              w2cs=src_w2cs,                                              intrinsics=src_intrinsics,                                              query_c2w=ref_c2w,                                              img_index=None,                                              rays_uv=rays_uv if color_patch_weight > 0 else None,                                              cos_anneal_ratio=self.udf_get_cos_anneal_ratio())            # 提取渲染结果中的各项信息            weight_sum = render_out['weight_sum']            color_base = render_out['color_base']            color = render_out['color']            color_pixel = render_out['color_pixel']            patch_colors = render_out['patch_colors']            patch_mask = (render_out['patch_mask'].float()[:, None] * (weight_sum > 0.5).float()) > 0. \                if render_out['patch_mask'] is not None else None            pixel_mask = mask if self.mask_weight > 0 else None            variance = render_out['variance']            beta = render_out['beta']            gamma = render_out['gamma']            gradient_error = render_out['gradient_error']            gradient_error_near_surface = render_out['gradient_error_near_surface']            sparse_error = render_out['sparse_error']            udf = render_out['udf']            udf_min = udf.min(dim=1)[0][mask[:, 0] > 0.5].mean()            # 计算颜色损失            color_losses = self.color_loss_func(                color_base, color, true_rgb, color_pixel,                pixel_mask, patch_colors, gt_patch_colors, patch_mask            )            # 提取各项颜色损失            color_total_loss = color_losses['loss']            color_base_loss = color_losses['color_base_loss']            color_loss = color_losses['color_loss']            color_pixel_loss = color_losses['color_pixel_loss']            color_patch_loss = color_losses['color_patch_loss']            # 计算PSNR（峰值信噪比）            psnr = 20.0 * torch.log10(                1.0 / (((color - true_rgb) ** 2 * mask).sum() / (mask_sum * 3.0)).sqrt())            # 计算遮罩损失            # mask_loss = (weight_sum - mask).abs().mean()            mask_loss = F.binary_cross_entropy(weight_sum.clip(1e-3, 1.0 - 1e-3), mask)            # 计算Eikonal损失            gradient_error_loss = gradient_error            # 设置遮罩权重            mask_weight = self.mask_weight            # 根据条件判断是否使beta可训练            if variance.mean() < 2 * beta.item() and variance.mean() < 0.01 and beta_flag and self.variance_network_fine.variance.requires_grad:                print("make beta trainable")                self.beta_network.set_beta_trainable()                beta_flag = False            # 根据迭代步数决定是否使变差网络可训练            if self.variance_network_fine.variance.requires_grad is False and self.iter_step > 20000:                self.variance_network_fine.set_trainable()            # 根据是否启用权重调度决定常规权重            if not self.reg_weights_schedule:                igr_ns_weight = self.igr_ns_weight                sparse_weight = self.sparse_weight            else:                igr_ns_weight, sparse_weight = self.udf_regularization_weights_schedule()    def udf_update_learning_rate(self, start_g_id=0):        if self.iter_step < self.warm_up_end:            learning_factor = self.iter_step / self.warm_up_end        else:            alpha = self.learning_rate_alpha            progress = (self.iter_step - self.warm_up_end) / (self.end_iter - self.warm_up_end)            learning_factor = (np.cos(np.pi * progress) + 1.0) * 0.5 * (1 - alpha) + alpha        for g in self.optimizer.param_groups[start_g_id:]:            g['lr'] = self.learning_rate * learning_factor    def udf_update_learning_rate_geo(self):        if self.iter_step < self.fix_geo_end:  # * make bg nerf learn first            learning_factor = 0.0        elif self.iter_step < self.warm_up_end * 2:            learning_factor = self.iter_step / (self.warm_up_end * 2)        elif self.iter_step < self.end_iter * 0.5:            learning_factor = 1.0        else:            alpha = self.learning_rate_alpha            progress = (self.iter_step - self.end_iter * 0.5) / (self.end_iter - self.end_iter * 0.5)            learning_factor = (np.cos(np.pi * progress) + 1.0) * 0.5 * (1 - alpha) + alpha        for g in self.optimizer.param_groups[:1]:            g['lr'] = self.learning_rate_geo * learning_factor    def udf_adjust_color_loss_weights(self):        if self.is_finetune:            factor = 1.0        else:            if self.iter_step < 10000:                factor = 0            elif self.iter_step < 20000:                factor = np.clip((self.iter_step - 10000) / 10000, 0, 1)            else:                factor = 1.        if self.color_base_weight < self.color_weight:            color_base_weight = self.color_base_weight * factor        else:            color_base_weight = self.color_base_weight        color_weight = self.color_weight        color_pixel_weight = self.color_pixel_weight * factor        color_patch_weight = self.color_patch_weight * factor        self.color_loss_func.set_color_weights(color_base_weight, color_weight, color_pixel_weight, color_patch_weight)        return color_base_weight, color_weight, color_pixel_weight, color_patch_weight    def udf_regularization_weights_schedule(self):        igr_ns_weight = 0.0        sparse_weight = 0.0        end1 = self.end_iter // 5        end2 = self.end_iter // 2        if self.iter_step >= end1:            igr_ns_weight = self.igr_ns_weight * np.clip((self.iter_step - end1) / end1, 0.0, 1.0)        if self.iter_step >= end2:            sparse_weight = self.sparse_weight        return igr_ns_weight, sparse_weight    def udf_get_flip_saturation(self, flip_saturation_max=0.9):        start = 10000        if self.iter_step < start:            flip_saturation = 0.0        elif self.iter_step < self.end_iter * 0.5:            flip_saturation = flip_saturation_max        else:            flip_saturation = 1.0        if self.is_finetune:            flip_saturation = 1.0        return flip_saturation    def udf_get_cos_anneal_ratio(self):        if self.anneal_end == 0.0:            return 1.0        else:            return np.min([1.0, self.iter_step / self.anneal_end])if __name__ == "__main__":    torch.set_default_tensor_type('torch.cuda.FloatTensor')    FORMAT = "[%(filename)s:%(lineno)s - %(funcName)20s() ] %(message)s"    logging.basicConfig(level=logging.DEBUG, format=FORMAT)    # 首先读取argumentss    args,lp,op,pp = parse_arguments()    args.save_iterations.append(args.iterations)    print("Optimizing " + args.model_path)    torch.cuda.set_device(args.gpu)    # Initialize system state (RNG)    safe_state(args.quiet)    torch.autograd.set_detect_anomaly(args.detect_anomaly)    # TODO Start GUI server, configure and run training    # network_gui.init(args.ip, args.port)    # 初始化trainer    # 后五个都是UDF的数据    trainer = Trainer(args, lp, op, pp, args.udfconf, args.mode, args.case, args.model_type, args.is_continue)    # 前8个参数都是在3dgs中设置的    # UDF    trainer.training(lp.extract(args),                     op.extract(args),                     pp.extract(args),                     args.test_iterations,                     args.save_iterations,                     args.checkpoint_iterations,                     args.start_checkpoint,                     args.debug_from)